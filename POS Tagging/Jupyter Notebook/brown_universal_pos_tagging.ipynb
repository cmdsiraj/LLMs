{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9673d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/siraj/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/siraj/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"universal_tagset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644342a",
   "metadata": {},
   "source": [
    "## Tags in Brown (Universal) corpus:\n",
    "- ADJ – Adjective (e.g., big, blue, fast)\n",
    "- ADP – Adposition (prepositions and postpositions, e.g., in, on, under)\n",
    "- ADV – Adverb (e.g., quickly, very, silently)\n",
    "- CONJ – Coordinating conjunction (e.g., and, but, or)\n",
    "- DET – Determiner (e.g., the, a, some, this)\n",
    "- NOUN – Noun (e.g., cat, city, book)\n",
    "- NUM – Numeral (e.g., one, 100, third)\n",
    "- PRON – Pronoun (e.g., he, she, it, they)\n",
    "- PRT – Particle (e.g., up, off, not — especially in phrasal verbs like \"shut up\")\n",
    "- VERB – Verb (e.g., run, is, jump, eaten)\n",
    "- . – Punctuation (e.g., ., !, ?)\n",
    "- X – Other (miscellaneous, foreign words, typos, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import train_test_split, extract_vocab, get_word_tag, preprocess_test, input_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f749ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = list(brown.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b2b0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 40138\n",
      "length of test set: 17202\n"
     ]
    }
   ],
   "source": [
    "train_l, test_l = train_test_split(tagged_sentences, test_size=0.3)\n",
    "\n",
    "print(f\"Length of train set: {len(train_l)}\")\n",
    "print(f\"length of test set: {len(test_l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9b4db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " : 0\n",
      "! : 1\n",
      "$.03 : 2\n",
      "$.07 : 3\n",
      "$.50 : 4\n",
      "$1 : 5\n",
      "$1,000 : 6\n",
      "$1,000,000 : 7\n",
      "$1,200 : 8\n",
      "$1,500 : 9\n",
      "$1,500,000 : 10\n",
      "$1.1 : 11\n",
      "$1.8 : 12\n",
      "$10 : 13\n",
      "$10,000 : 14\n",
      "$10.50 : 15\n",
      "$100 : 16\n",
      "$100,000 : 17\n",
      "$110 : 18\n",
      "$12,500 : 19\n",
      "$125 : 20\n"
     ]
    }
   ],
   "source": [
    "vocab = extract_vocab(train_l)\n",
    "\n",
    "cnt = 0\n",
    "for k, v in vocab.items():\n",
    "    print(f\"{k} : {v}\")\n",
    "    cnt+=1\n",
    "    if cnt>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947c55e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Keith',\n",
       " 'was',\n",
       " 'an',\n",
       " 'eagle',\n",
       " '.',\n",
       " '--n--',\n",
       " 'Mark',\n",
       " 'the',\n",
       " 'specimen',\n",
       " 'at',\n",
       " 'the',\n",
       " 'outer',\n",
       " 'edges',\n",
       " 'of',\n",
       " 'the',\n",
       " 'template',\n",
       " 'with',\n",
       " 'pen',\n",
       " 'and',\n",
       " 'indelible']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences, test_set = preprocess_test(test_l, vocab)\n",
    "\n",
    "test_sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33894640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionaries(train_l, vocab):\n",
    "\n",
    "    emission_count = defaultdict(int)\n",
    "    transitions_count = defaultdict(int)\n",
    "    tag_count = defaultdict(int)\n",
    "\n",
    "    prev_tag = \"--s--\"\n",
    "\n",
    "    for line in train_l:\n",
    "        word, tag = get_word_tag((\"\\n\", \"\\n\"), vocab)\n",
    "        emission_count[(tag, word)] += 1\n",
    "        transitions_count[(prev_tag, tag)] += 1\n",
    "        tag_count[tag] += 1\n",
    "        prev_tag = tag\n",
    "        for word_tag in line:\n",
    "\n",
    "            word, tag = get_word_tag(word_tag, vocab)\n",
    "\n",
    "            emission_count[(tag, word)] += 1\n",
    "\n",
    "            transitions_count[(prev_tag, tag)] += 1\n",
    "\n",
    "            tag_count[tag] += 1\n",
    "\n",
    "            prev_tag = tag\n",
    "    \n",
    "    return emission_count, transitions_count, tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a49e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_counts, transition_counts, tag_counts = create_dictionaries(train_l, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763f496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POS tags (number of 'states'): 13\n",
      "View these POS tags (states)\n",
      "['--s--', '.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "states = sorted(tag_counts.keys())\n",
    "print(f\"Number of POS tags (number of 'states'): {len(states)}\")\n",
    "print(\"View these POS tags (states)\")\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52de95f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition examples: \n",
      "(('--s--', '--s--'), 1)\n",
      "(('--s--', 'DET'), 8566)\n",
      "(('DET', 'NOUN'), 59870)\n",
      "\n",
      "emission examples: \n",
      "(('NOUN', 'suits'), 12)\n",
      "(('VERB', 'filed'), 22)\n",
      "(('ADJ', 'several'), 235)\n",
      "\n",
      "ambiguous word example: \n",
      "('ADV', 'back') 497\n",
      "('NOUN', 'back') 121\n",
      "('ADJ', 'back') 20\n",
      "('VERB', 'back') 17\n"
     ]
    }
   ],
   "source": [
    "print(\"transition examples: \")\n",
    "for ex in list(transition_counts.items())[:3]:\n",
    "    print(ex)\n",
    "print()\n",
    "\n",
    "print(\"emission examples: \")\n",
    "for ex in list(emission_counts.items())[200:203]:\n",
    "    print (ex)\n",
    "print()\n",
    "\n",
    "print(\"ambiguous word example: \")\n",
    "for tup,cnt in emission_counts.items():\n",
    "    if tup[1] == 'back': print (tup, cnt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7578c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(transition_counts, alpha, tag_counts):\n",
    "    \n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(all_tags)\n",
    "\n",
    "    transition_matrix = np.zeros((num_tags, num_tags))\n",
    "\n",
    "    trans_key = set(transition_counts.keys())\n",
    "\n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_tags):\n",
    "            count = 0\n",
    "\n",
    "            key = (all_tags[i], all_tags[j])\n",
    "\n",
    "            if key in trans_key:\n",
    "                count = transition_counts[key]\n",
    "            \n",
    "            transition_matrix[i, j] = (count+alpha)/(tag_counts[all_tags[i]] + num_tags*alpha)\n",
    "    \n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13ecae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A at row 0, col 0: 0.000024939\n",
      "A at row 3, col 1: 0.0099\n",
      "View a subset of transition matrix A\n",
      "           PRT      VERB         X\n",
      "PRT   0.011875  0.621546  0.000096\n",
      "VERB  0.065942  0.183862  0.000189\n",
      "X     0.008575  0.057878  0.505889\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "A = create_transition_matrix(transition_counts, alpha, tag_counts)\n",
    "\n",
    "print(f\"A at row 0, col 0: {A[0,0]:.9f}\")\n",
    "print(f\"A at row 3, col 1: {A[3,1]:.4f}\")\n",
    "\n",
    "print(\"View a subset of transition matrix A\")\n",
    "A_sub = pd.DataFrame(A[10:15,10:15], index=states[10:15], columns = states[10:15] )\n",
    "print(A_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9662c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_matrix(emission_counts, alpha, tag_counts, vocab: list):\n",
    "    \n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(all_tags)\n",
    "\n",
    "    num_words = len(vocab)\n",
    "\n",
    "    emission_matrix = np.zeros((num_tags, num_words))\n",
    "\n",
    "    emis_keys = set(emission_counts.keys())\n",
    "\n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_words):\n",
    "            count = 0\n",
    "            \n",
    "            key = (all_tags[i], vocab[j])\n",
    "\n",
    "            if key in emis_keys:\n",
    "                count = emission_counts[key]\n",
    "            \n",
    "            emission_matrix[i, j] = (count+alpha)/(tag_counts[all_tags[i]]+alpha*num_words)\n",
    "    \n",
    "    return emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c6406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Matrix position at row 0, column 0: 0.000000025\n",
      "View Matrix position at row 3, column 1: 0.000000010\n",
      "              $100     Available       comrade      relaxing       Dryfoos\n",
      "ADJ   1.702329e-08  6.811019e-05  1.702329e-08  1.702329e-08  1.702329e-08\n",
      "DET   1.044582e-08  1.044582e-08  1.044582e-08  1.044582e-08  1.044582e-08\n",
      "PRON  2.927225e-08  2.927225e-08  2.927225e-08  2.927225e-08  2.927225e-08\n",
      "VERB  7.860829e-09  7.860829e-09  7.860829e-09  2.359035e-05  7.860829e-09\n",
      "X     1.043790e-06  1.043790e-06  1.043790e-06  1.043790e-06  1.043790e-06\n",
      "PRT   4.782390e-08  4.782390e-08  4.782390e-08  4.782390e-08  4.782390e-08\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "B = create_emission_matrix(emission_counts, alpha, tag_counts, list(vocab))\n",
    "\n",
    "print(f\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\")\n",
    "print(f\"View Matrix position at row 3, column 1: {B[3,1]:.9f}\")\n",
    "\n",
    "# Try viewing emissions for a few words in a sample dataframe\n",
    "cidx  = ['$100','Available','comrade', 'relaxing', 'Dryfoos']\n",
    "\n",
    "# Get the integer ID for each word\n",
    "cols = [vocab[a] for a in cidx]\n",
    "\n",
    "# Choose POS tags to show in a sample dataframe\n",
    "rvals =['ADJ','DET','PRON', 'VERB','X','PRT']\n",
    "\n",
    "# For each POS tag, get the row number from the 'states' list\n",
    "rows = [states.index(a) for a in rvals]\n",
    "\n",
    "# Get the emissions for the sample of words, and the sample of POS tags\n",
    "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )\n",
    "print(B_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa15e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_initialize(A, B, vocab, tag_counts, states, corpus):\n",
    "\n",
    "    num_tags = len(tag_counts.keys())\n",
    "\n",
    "    best_probs = np.zeros((num_tags, len(corpus)))\n",
    "\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
    "\n",
    "    s_indx = states.index(\"--s--\")\n",
    "\n",
    "    for i in range(num_tags):\n",
    "\n",
    "        if A[s_indx, i] == 0:\n",
    "            best_probs[i,0] = float('-inf')\n",
    "        else:\n",
    "            best_probs[i,0] = math.log(A[s_indx, i])+math.log(B[i, vocab[corpus[0]]])\n",
    "    \n",
    "    return best_probs, best_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55fc46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs, best_paths = viterbi_initialize(A, B, vocab, tag_counts, states, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96b57e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,0]: -28.1075\n",
      "best_paths[2,3]: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_probs[0,0]: {best_probs[0,0]:.4f}\")\n",
    "print(f\"best_paths[2,3]: {best_paths[2,3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6000274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(best_probs, best_paths, A, B, vocab, corpus):\n",
    "    \n",
    "    num_tags = best_probs.shape[0]\n",
    "\n",
    "    for i in range(1, len(corpus)):\n",
    "        \n",
    "        for j in range(num_tags):\n",
    "            best_prob_i = float(\"-inf\")\n",
    "            best_path_i = None\n",
    "\n",
    "            for k in range(num_tags):\n",
    "                prob = best_probs[k, i-1] + math.log(A[k, j]) + math.log(B[j, vocab[corpus[i]]])\n",
    "\n",
    "                if prob > best_prob_i:\n",
    "                    best_prob_i = prob\n",
    "                    best_path_i = k\n",
    "                \n",
    "            best_probs[j, i] = best_prob_i\n",
    "            best_paths[j, i] = best_path_i\n",
    "    \n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ed2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs, best_paths = viterbi_forward(best_probs, best_paths, A, B, vocab, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02df6238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0, 1]: -34.5624\n",
      "best_paths[0,1]: 7\n",
      "--------\n",
      "best_probs[2, 1]: -33.5933\n",
      "best_paths[2, 1]: 7\n",
      "--------\n",
      "best_probs[9, 20]: -157.5209\n",
      "best_paths[9, 20]: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_probs[0, 1]: {best_probs[0,1]:.4f}\")\n",
    "print(f\"best_paths[0,1]: {best_paths[0,1]}\")\n",
    "print(\"--------\")\n",
    "print(f\"best_probs[2, 1]: {best_probs[2,1]:.4f}\")\n",
    "print(f\"best_paths[2, 1]: {best_paths[2,1]}\")\n",
    "print(\"--------\")\n",
    "print(f\"best_probs[9, 20]: {best_probs[9,20]:.4f}\")\n",
    "print(f\"best_paths[9, 20]: {best_paths[9,20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b7a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, states):\n",
    "\n",
    "    num_words = best_probs.shape[1]\n",
    "\n",
    "    z = np.zeros(num_words, dtype=int)\n",
    "\n",
    "    pred = [None] * num_words\n",
    "\n",
    "    last_tag_index = np.argmax(best_probs[:,num_words-1])\n",
    "    z[num_words-1] = last_tag_index\n",
    "    pred[num_words-1] = states[last_tag_index]\n",
    "\n",
    "    for i in range(num_words-1, 0, -1):\n",
    "        z[i-1] = best_paths[z[i], i]\n",
    "        pred[i-1] = states[z[i-1]]\n",
    "    \n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ec3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = viterbi_backward(best_probs, best_paths, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72ac5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for word, pred_tag in zip(test_sentences, pred):\n",
    "    predictions.append((word, pred_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f863db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(test_set, pred_set):\n",
    "    correct_count = 0\n",
    "    for t, p in zip(test_set, pred_set):\n",
    "        if t[1]==p[1]:\n",
    "            correct_count+=1\n",
    "    \n",
    "    return correct_count/len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3174ade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Keith', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('eagle', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('--n--', '--s--'),\n",
       " ('Mark', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('specimen', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('outer', 'ADJ'),\n",
       " ('edges', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('template', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('pen', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('indelible', 'ADJ'),\n",
       " ('ink', 'NOUN'),\n",
       " (';', '.'),\n",
       " (';', '.'),\n",
       " ('--n--', '--s--'),\n",
       " ('The', 'DET'),\n",
       " ('--unk_upper--', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('purely', 'ADV'),\n",
       " ('a', 'DET'),\n",
       " ('--unk_noun--', 'NOUN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc65edf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Keith', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('eagle', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('--n--', '--s--'),\n",
       " ('Mark', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('specimen', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('outer', 'ADJ'),\n",
       " ('edges', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('template', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('pen', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('indelible', 'ADJ'),\n",
       " ('ink', 'NOUN'),\n",
       " (';', '.'),\n",
       " (';', '.'),\n",
       " ('--n--', '--s--'),\n",
       " ('The', 'DET'),\n",
       " ('Creston', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('purely', 'ADV'),\n",
       " ('a', 'DET'),\n",
       " ('potboiler', 'NOUN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb20f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.29325375992515\n"
     ]
    }
   ],
   "source": [
    "accuaracy = calculate_accuracy(test_set, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuaracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38ccaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_POS(A, B, input: str, vocab, tag_counts, states):\n",
    "    corpus = input_preprocess(input, vocab)\n",
    "    best_probs, best_paths = viterbi_initialize(A, B, vocab, tag_counts, states, corpus)\n",
    "    best_probs, best_paths = viterbi_forward(best_probs, best_paths, A, B, vocab=vocab, corpus=corpus)\n",
    "    predictions = viterbi_backward(best_probs, best_paths, states)\n",
    "\n",
    "    word_tag_predictions = []\n",
    "    for word, tag in zip(corpus, predictions):\n",
    "        word_tag_predictions.append((word, tag))\n",
    "    \n",
    "    return word_tag_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "302f1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_words(input: str):\n",
    "    return tag_POS(A, B, input, vocab, tag_counts, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4622186",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"hi gpt, my name is sathvik.\n",
    "I resigned to einstein. is it a good idea?\"\"\"\n",
    "\n",
    "preds = tag_words(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f7dc22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--unk_adj--', 'ADJ'),\n",
       " ('--unk--', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('my', 'DET'),\n",
       " ('name', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('--unk--', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRON'),\n",
       " ('resigned', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('--unk--', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('a', 'DET'),\n",
       " ('good', 'ADJ'),\n",
       " ('idea', 'NOUN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2bb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
